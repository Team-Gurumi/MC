# Team-Info

| 항목 | 내용 |
|:---|:---|
| **(1) 과제명** | **P2P 기반 분산형 클라우드를 이용한 소규모 조직의 유휴 컴퓨팅 자원 공유 시스템**<br>(A P2P-based Distributed Cloud System for Sharing Idle Computing Resources in Small-scale Organizations) |
| **(2) 팀 번호 / 팀 이름** | 09-구르미 |
| **(3) 팀 구성원** | 금채원(2276029): 팀장, 실험 환경 구축, 아키텍처 성능 실험, 문서화·산출물 관리<br>이서영(2276218): 팀원, 아키텍처 설계 주도, 실험 환경 구축, 설계 검토·피드백<br>송예린(2171023): 팀원, 실험 환경 구축, 기술 검증, 성능 분석, 블록체인 도입 검토 |
| **(4) 팀 지도교수** | 반효경 교수 |
| **(5) 팀 멘토** | - |
| **(6) 과제 분류** | 연구 과제 |
| **(7) 과제 키워드** | Mutual Cloud, Resource Sharing, P2P Network, DHT, Self-Healing |
| **(8) 과제 내용 요약** | 본 연구는 중앙집중형 클라우드의 단일 장애점(SPOF)과 자원 활용 비효율 문제를 해결하기 위해, **분산 해시 테이블(DHT)** 기반의 자율 제어 구조를 갖춘 **P2P 분산 자원 관리 프레임워크 Mutual Cloud**를 제안한다. Mutual Cloud는 중앙 제어기 없이 모든 노드가 동시에 자원의 공급자(Provider)와 소비자(Consumer)로 동작하며, 상태 정보를 DHT에 공유하여 작업을 탐색·임대·복구한다. XOR 기반 라우팅과 Lease–Heartbeat–Fencing 절차를 통해 장애를 자동 감지·복구(Self-healing)하며, 중앙집중형 제어 구조의 병목을 제거한다. Docker 테스트베드 실험 결과, 에이전트 수가 50→500으로 증가해도 MTTR p95가 48.07초에서 0.28초로 감소하고, 40% 노드 장애 상황에서도 100% 작업 성공률을 유지함을 확인하였다. 이를 통해 Mutual Cloud가 소규모 조직 환경에서 **경제적·안정적·자율형 인프라 대안**으로서의 가능성을 입증하였다. |
| **(9) 주요 Link** | 과제 GitHub: [https://github.com/Team-Gurumi/MC](https://github.com/Team-Gurumi/MC) |
| **(10) 기타** | Docker 기반 실험 환경, P2P QUIC 통신, PostgreSQL 기반 상태 저장 구조 사용 |


---

# Project-Summary

| 항목 | 내용 |
|:---|:---|
| **(1) 문제 정의** | 대부분의 클라우드 인프라는 **중앙집중형 제어 평면(Centralized Control Plane)** 에 의존한다. 이 구조는 마스터–워커 형태로 중앙 서버가 모든 스케줄링과 자원 제어를 수행하기 때문에, 단일 장애점(SPOF)과 제어 부하 집중(Bottleneck) 문제가 발생한다. 특히 제어기 장애나 네트워크 단절 시 전체 작업이 중단되며, 복구 과정에서 리더 선출(Leader Election)과 상태 동기화 지연으로 인해 복구 시간이 증가한다. 또한 중앙 집중 구조는 서로 다른 기관 간 유휴 자원 공유가 어려워 확장성과 경제성이 제한된다. 본 연구는 이러한 문제를 해결하기 위해, 중앙 제어기를 제거하고 각 노드가 자율적으로 자원 제어를 수행하는 **P2P 기반 탈중앙화 클라우드 제어 평면(Decentralized Control Plane)** 을 구현하였다. |
| **(2) 기존 연구와의 비교** | 기존 오케스트레이션 시스템(Kubernetes, OpenStack 등)은 고가용성(HA) 구조를 통해 복제 제어기를 두지만, 여전히 중앙 제어 평면에 의존한다. 반면 Mutual Cloud는 **제어 기능을 완전히 분산화**하여 중앙 제어기의 장애가 전체 시스템 중단으로 이어지지 않는다. 기존 연구는 주로 DHT를 데이터 저장소로 활용하였으나, Mutual Cloud는 DHT를 제어 평면에 통합하여 **작업 임대(Lease), 하트비트(Heartbeat), 펜싱(Fencing)** 로직을 자율적으로 수행하도록 설계하였다. 또한 제어 트래픽을 분산시켜 대규모 환경에서도 O(log N) 복잡도로 탐색과 제어가 가능하다. |
| **(3) 제안 내용** | Mutual Cloud는 **DHT 기반 자율 분산 자원 관리 프레임워크**로, 중앙 제어 없이 모든 노드가 자원을 등록·탐색·임대·복구한다. 각 노드는 DHT에 상태를 `/ns/node/<NodeID>/meta`, `/ns/node/<NodeID>/lease`, `/ns/task/<TaskID>/state` 구조로 저장한다. XOR 기반 라우팅을 통해 노드 간 탐색을 O(log N)으로 수행하고, Lease–Heartbeat–Fencing 절차로 장애를 자동 감지 및 복구한다. DHT는 제어 트래픽을 균등하게 분산시켜 네트워크가 커져도 탐색 지연이 일정하게 유지된다. 이 구조를 통해 Mutual Cloud는 **SPOF 제거, 자율 복구(Self-healing), 선형 확장성(Scalability)** 을 모두 달성하였다. |
| **(4) 기대효과 및 의의** | 1. **SPOF 제거**: 중앙 제어기 없이도 모든 노드가 제어 기능 수행 가능<br>2. **자율 복구(Self-healing)**: 장애 감지 시 자동 재임대(Re-Claim)로 시스템 연속성 유지<br>3. **확장성(Scalability)**: 에이전트 수 증가에도 MTTR이 안정적으로 유지<br>4. **자원 활용률 향상**: 유휴 자원 공유로 TCO(총소유비용) 절감<br>5. **정책 자율성 확보**: 기관 간 협력형 분산 인프라로 확장 가능 |
| **(5) 주요 기능 리스트** | - **DHT 자원 등록 및 탐색**: 각 노드가 자원 상태를 분산 저장<br>- **Lease 관리 및 펜싱(Fencing)**: 작업 점유권 충돌 방지<br>- **Heartbeat 기반 장애 감지 및 자율 복구**<br>- **DB 기반 상태 동기화 (PostgreSQL)**<br>- **WebSocket 실시간 로그 스트리밍**<br>- **Docker 기반 테스트베드 구성 및 시각화 실험 도구** |


---

# Project-Design & Implementation
<table>
<tr>
<th>(1) 요구사항 정의</th>
</tr>
<tr>
<td>

Mutual Cloud는 다음의 요구사항을 충족해야 한다:  
① 중앙 제어기 없이도 자원의 등록·탐색·임대가 가능해야 함  
② 장애 발생 시 자동 복구(Self-healing) 수행  
③ 작업 상태(lease, fencing version, heartbeat)가 DHT 및 DB 모두에서 일관성 유지  
④ 시스템 확장 시 MTTR 및 Success Rate의 안정성 보장  
⑤ 컨테이너 기반 실험 환경에서 재현 가능해야 함  

</td>
</tr>
</table>

---

<table>
<tr>
<th>(2) 전체 시스템 구성</th>
</tr>
<tr>
<td>

뮤츄얼 클라우드 시스템은 세 개의 논리적 계층으로 구성된다:  
1) 상위 계층 (클라이언트–컨트롤–데이터베이스),  
2) 중간 계층 (DHT 네트워크),  
3) 하위 계층 (에이전트–시더 상호작용).

<br><br>

### 🧩 ① 상위 계층 (Client, Control, DB)
<img src="./assignment/images/upper_layer.png" width="700"><br>
<b>그림 3-1.</b> 클라이언트–컨트롤–데이터베이스 간 상호작용을 나타내는 상위 계층 구조.

<br><br>

### 🧩 ② 중간 계층 (DHT Network)
<img src="./assignment/images/middle_layer.png" width="700"><br>
<b>그림 3-2.</b> 컨트롤, 에이전트, 시더가 피어로 참여하는 탈중앙화 DHT 구조를 나타내는 중간 계층 아키텍처.

<br><br>

### 🧩 ③ 하위 계층 (Agent–Seeder Interaction)
<img src="./assignment/images/lower_layer.png" width="700"><br>
<b>그림 3-3.</b> 에이전트와 시더 간의 P2P 데이터 흐름 및 컨트롤–데이터베이스 보고 경로를 나타내는 하위 계층 구조.

</td>
</tr>
</table>

---

<table>
<tr>
<th>(3) 주요 엔진 및 기능 설계</th>
</tr>
<tr>
<td>

- **언어 및 프레임워크:** Go(lang), libp2p, go-libp2p-kad-dht  
- **DB 스키마:** `demand_jobs(id, image, command, status, lease_token, ttl_sec, metrics)`  
- **통신 구조:** QUIC 기반 P2P + HTTP/gRPC  
- **모듈 구성:** pkg/dht, pkg/agent, pkg/control, pkg/demand, internal/seeder  
- **자율 복구 알고리즘:** Lease–Heartbeat–Fencing 절차를 통한 중복 방지 및 복원  
- **테스트 환경:** Docker Compose 기반 컨테이너 클러스터 (Control/Seeder/Agents)

</td>
</tr>
</table>

---

<table>
<tr>
<th>(4) 주요 기능의 구현</th>
</tr>
<tr>
<td>

① **SPOF 제거 검증 실험**  
Control 서버 장애 시에도 Agent가 독립적으로 작업을 완료  
→ 장애 구간(75~105초) 동안에도 succeeded 작업이 지속 증가  
→ 서버 재시작 후 DB 복구 및 정상 상태 전환  

<br>

② **확장성 평가**  
Agent 수를 50→500으로 증가시켜도 Success Rate 100%, MTTR 48.07→0.28초  

<br>

③ **장애 내성 평가**  
Kill 비율 10–60% 증가 시에도 Success Rate 100%,  
40% 장애에서도 MTTR 22.67초 유지  

</td>
</tr>
</table>

---

<table>
<tr>
<th>(5) 기타</th>
</tr>
<tr>
<td>

Mutual Cloud는 중앙 제어기 의존 없이도 확장성, 복원력, 자율성을 갖춘  
분산형 클라우드 제어 모델을 실험적으로 입증하였다.  
향후 다중 기관 간 **Federated Mutual Cloud**로 확장하여,  
정책 일관성 유지와 신뢰 확장형 협력 클라우드로 발전시킬 계획이다.

</td>
</tr>
</table>
